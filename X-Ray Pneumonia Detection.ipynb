{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10: X-Ray Pneumonia Detection (M.Sc Students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write*\n",
    "* *Tuo ZHANG* \n",
    "* *matr. nr.* \n",
    "* *Computational Linguistics*\n",
    "* M.Sc.\n",
    "\n",
    "*of all assignment group participants here. (double klick here to edit)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this assignment, you are tasked with developing your own classifier for pneumonia in X-ray images. You will go through to the complete ML development cycle from loading and preprocessing your data to evaluating your models.\n",
    "\n",
    "Extract the X-Ray dataset https://rssiste.sharepoint.com/:u:/s/analyticcomputing/ERMTk8Wm091Crev9tV0NEBUBv7ue3bRSG8iiftCCjbOKhA?e=UcjaFB to the same directory as your Jupyter notebook. The data is already split into a training, validation, and testing set. The dataset originates from the paper [Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning\n",
    "](https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5).\n",
    "\n",
    "You may use any packages, we encountered during the exercises (numpy, matplotlib, scikit-learn, scikit-image, pandas, pytorch) as well as the Python standard library.\n",
    "\n",
    "You should (at least) address the following points in your development process:\n",
    "\n",
    "- The dataset is imbalanced. Do at least one of the following:\n",
    "    - Augment your dataset by including rotated, flipped, or brightened images. This will also improve the generalization capabilities of your model.\n",
    "    - or: Modify your objective function by weighting the classes differently.\n",
    "- Optimize the hyperparameters of your models using grid-search or random-search on the validation set.\n",
    "- Consider at least two classes of models, e.g. CNN and SVM. At least one of your model classes should be some type of neural network implemented in PyTorch.\n",
    "- After the hyperparameter optimization, select the best-performing models of each class. Evaluate these models on the testing data and visualize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points (200):\n",
    "\n",
    "    1. Model Definitions and Training : 80\n",
    "    2. Model Evaluations : 80\n",
    "    3. Data Augmentation and Hyperparameter Searching : 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*! \n",
    "\n",
    "This assignment scores (200) counts in 60% threshold (from all 10 assignment, including this project) to be passed for exam. If you already have enough scores then you are not obliged to complete this project (i.e. you already have more than 60% of ALL scores from previous assignment, again, including this project). Otherwise you should do this assignments that it provide double of usual points (200); thus it can increase the overall submisson score. \n",
    "\n",
    "For example, if you have more than 660 points out of 1100 total (900-previous assignment + 200-this assignment), then you do not have to perform the assignment . You can consult all of your accumulated points in Illias.\n",
    "\n",
    "\n",
    "You have two weeks to complete this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch  # Package name: torch (for pip), pytorch (for conda)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    import os\n",
    "\n",
    "    def load_data(directory):\n",
    "        directories = (d for d in os.listdir(directory)\n",
    "                       if os.path.isdir(os.path.join(directory, d)))\n",
    "        labels = []\n",
    "        images = []\n",
    "        count_1 = 0\n",
    "        count_2 = 0\n",
    "        for d in directories:\n",
    "            label_directory = os.path.join(directory, d)\n",
    "            file_names = (os.path.join(label_directory, f)\n",
    "                          for f in os.listdir(label_directory)\n",
    "                          if f.endswith(\".jpeg\"))\n",
    "            count_1 = count_1 + 1\n",
    "            for f in file_names:\n",
    "                images.append(cv2.imread(f, cv2.IMREAD_GRAYSCALE))\n",
    "                if d == \"NORMAL\":\n",
    "                    labels.append(0)\n",
    "                elif d == \"PNEUMONIA\":\n",
    "                    labels.append(1)\n",
    "                count_2 = count_2 + 1\n",
    "        images, labels = np.array(images), np.array(labels)\n",
    "        images = np.array([cv2.resize(img, (50, 50)) for img in images])\n",
    "        return images, labels\n",
    "\n",
    "    X_train, y_train = load_data('chest_xray/train')\n",
    "    X_test, y_test = load_data('chest_xray/test')\n",
    "    X_val, y_val = load_data('chest_xray/val')\n",
    "\n",
    "    '''note that as the input image is greyscale, we have to add one dimension to the array representation of the \n",
    "    image(input channel is 1) so it can be later correctly processed by pytorch '''\n",
    "    # np.savez('dataset.npz', X_train=X_train[..., np.newaxis], X_test=X_test[..., np.newaxis], X_val=X_val[..., np.newaxis], y_train=y_train, y_test=y_test, y_val=y_val)\n",
    "    return X_train[..., np.newaxis], X_test[..., np.newaxis], X_val[..., np.newaxis], y_train, y_test, y_val\n",
    "\n",
    "\n",
    "class BasicDataset(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "\n",
    "def train_image_classifier(model, dataset, learning_rate, batch_size, epochs, device):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        data_loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch in data_loader:\n",
    "            model.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "            yhat = model.forward(batch['X'].float().to(device))\n",
    "\n",
    "            batch_loss = F.cross_entropy(yhat, batch['y'].long().to(device))\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch == 0) or (((epoch + 1) % 10) == 0):\n",
    "            print(f'Epoch {epoch + 1}/{epochs} - Loss: {epoch_loss}')\n",
    "\n",
    "            \n",
    "class ImageDataset(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.moveaxis(X, -1, 1)\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return dict(X=self.X[idx], y=self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # You can figure out this number by printing the shape of the previous layer.\n",
    "        self.fc1 = nn.Linear(16 * 9 * 9, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 62)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(x.shape) to figure out the size of your linear layer\n",
    "        x = x.view(-1, 16 * 9 * 9)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5216\n",
      "Testing samples: 624\n",
      "Image shape: (50, 50, 1)\n",
      "#Classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data.\n",
    "'''You can uncomment the line of code below to read the data directly, but it is not recommended as it will take a \n",
    "very long time, see the function load_dataset() to check how the original images are resized and saved as numpy array'''\n",
    "# X_train, X_test, X_val, y_train, y_test, y_val = load_dataset()\n",
    "\n",
    "dataset = np.load('dataset.npz')\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = dataset['X_train'], dataset['X_test'], dataset['X_val'], \\\n",
    "                                                 dataset['y_train'], dataset['y_test'], dataset['y_val']\n",
    "print('Training samples:', X_train.shape[0])\n",
    "print('Testing samples:', X_test.shape[0])\n",
    "print('Image shape:', X_train[0].shape)\n",
    "print('#Classes:', len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Loss: 51.454414546489716\n",
      "Epoch 10/100 - Loss: 1.0653930380940437\n",
      "Epoch 20/100 - Loss: 0.3174277297803201\n",
      "Epoch 30/100 - Loss: 0.5307612037286162\n",
      "Epoch 40/100 - Loss: 0.33054596494184807\n",
      "Epoch 50/100 - Loss: 0.1766279524890706\n",
      "Epoch 60/100 - Loss: 0.0005869783999514766\n",
      "Epoch 70/100 - Loss: 0.00032407975322712446\n",
      "Epoch 80/100 - Loss: 0.00020893043540581857\n",
      "Epoch 90/100 - Loss: 0.00014561474381480366\n",
      "Epoch 100/100 - Loss: 0.00010678852504497627\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "device = torch.device('cuda')\n",
    "cnn = CNN().to(device)\n",
    "dataset = ImageDataset(X_train, y_train)\n",
    "learning_rate = 0.005\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "train_image_classifier(cnn, dataset, learning_rate, batch_size, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.805\n",
      "Recall: 0.742\n",
      "F1-score: 0.699\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "dataset_test = ImageDataset(X_test, y_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X = torch.from_numpy(np.array([sample['X'] for sample in dataset_test])).float().to(device)\n",
    "    yhat_unnormalized = cnn.forward(X).detach().cpu().numpy()\n",
    "\n",
    "yhat = np.argmax(yhat_unnormalized, axis=1)\n",
    "y = np.array([sample['y'] for sample in dataset_test])\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y, yhat, average='weighted')\n",
    "\n",
    "print(f'Precision: {prec:.03}')\n",
    "print(f'Recall: {rec:.03}')\n",
    "print(f'F1-score: {f1:.03}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1341, 3875], dtype=int64))\n",
      "Training samples: 2682\n",
      "Testing samples: 624\n",
      "Image shape: (50, 50, 1)\n",
      "#Classes: 2\n"
     ]
    }
   ],
   "source": [
    "# training and evaluation with data augmentation\n",
    "'''above I have done the training and evaluation without data augmentation, below, I will repeat the process again \n",
    "but with data augmentation '''\n",
    "\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "'''note the printed result above and with some simple testing, it is not difficult to see that the first 1341 samples are \n",
    "normal and the rest 3875 are pneumonia, my method of data augmentation is doing undersampling of the majority class'''\n",
    "length_of_minority_class = 1341\n",
    "X_pneumonia = X_train[length_of_minority_class:]\n",
    "X_pneumonia_undersampled = np.zeros((length_of_minority_class, 50, 50, 1), dtype=float)\n",
    "y_pneumonia_undersampled = np.zeros(length_of_minority_class, dtype=int)\n",
    "import random\n",
    "index_list = sorted(random.sample(range(3875), length_of_minority_class))\n",
    "\n",
    "for i in range(length_of_minority_class):\n",
    "    X_pneumonia_undersampled[i] = X_pneumonia[index_list[i]]\n",
    "    y_pneumonia_undersampled[i] = 1\n",
    "\n",
    "X_train_augmented = np.concatenate((X_train[:length_of_minority_class], X_pneumonia_undersampled), axis=0)\n",
    "y_train_augmented = np.concatenate((y_train[:length_of_minority_class], y_pneumonia_undersampled), axis=0)\n",
    "print('Training samples:', X_train_augmented.shape[0])\n",
    "print('Testing samples:', X_test.shape[0])\n",
    "print('Image shape:', X_train_augmented[0].shape)\n",
    "print('#Classes:', len(np.unique(y_train_augmented)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Loss: 81.74185240268707\n",
      "Epoch 10/100 - Loss: 3.217377334833145\n",
      "Epoch 20/100 - Loss: 1.962774708867073\n",
      "Epoch 30/100 - Loss: 1.6188807860016823\n",
      "Epoch 40/100 - Loss: 1.1732525676488876\n",
      "Epoch 50/100 - Loss: 0.8777704685926437\n",
      "Epoch 60/100 - Loss: 0.8536972030997276\n",
      "Epoch 70/100 - Loss: 0.6338348351418972\n",
      "Epoch 80/100 - Loss: 0.5879975091665983\n",
      "Epoch 90/100 - Loss: 0.3624602062627673\n",
      "Epoch 100/100 - Loss: 0.33988139778375626\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "cnn = CNN().to(device)\n",
    "dataset = ImageDataset(X_train_augmented, y_train_augmented)\n",
    "learning_rate = 0.005\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "train_image_classifier(cnn, dataset, learning_rate, batch_size, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.832\n",
      "Recall: 0.816\n",
      "F1-score: 0.804\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "dataset_test = ImageDataset(X_test, y_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X = torch.from_numpy(np.array([sample['X'] for sample in dataset_test])).float().to(device)\n",
    "    yhat_unnormalized = cnn.forward(X).detach().cpu().numpy()\n",
    "\n",
    "yhat = np.argmax(yhat_unnormalized, axis=1)\n",
    "y = np.array([sample['y'] for sample in dataset_test])\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y, yhat, average='weighted')\n",
    "\n",
    "print(f'Precision: {prec:.03}')\n",
    "print(f'Recall: {rec:.03}')\n",
    "print(f'F1-score: {f1:.03}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
